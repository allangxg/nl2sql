{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d14be392-06e1-47e5-9b9a-16a7d0fe365e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup mRAT-SQL + GAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd9461cb-fcbd-486f-afaa-1fbc7072434a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'gap-text2sql'...\n",
      "remote: Enumerating objects: 835, done.\u001b[K\n",
      "remote: Counting objects: 100% (835/835), done.\u001b[K\n",
      "remote: Compressing objects: 100% (534/534), done.\u001b[K\n",
      "remote: Total 835 (delta 451), reused 652 (delta 275), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (835/835), 3.66 MiB | 6.49 MiB/s, done.\n",
      "Resolving deltas: 100% (451/451), done.\n"
     ]
    }
   ],
   "source": [
    "# Download do projeto mRAT-SQL+GAP que serÃ£o usados os arquivos traduzidos do conjunto de dados SPIDER\n",
    "!git clone https://github.com/C4AI/gap-text2sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f550d5b-8aea-429a-b217-f1d71ead05bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/gap-text2sql/mrat-sql-gap\n"
     ]
    }
   ],
   "source": [
    "%cd gap-text2sql/mrat-sql-gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "921f0dca-0bfd-441d-a3a5-e0a8a40dabca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/conda/envs/mtext2sql\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.7\n",
      "\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _libgcc_mutex      conda-forge/linux-64::_libgcc_mutex-0.1-conda_forge\n",
      "  _openmp_mutex      conda-forge/linux-64::_openmp_mutex-4.5-1_gnu\n",
      "  ca-certificates    conda-forge/linux-64::ca-certificates-2021.10.8-ha878542_0\n",
      "  ld_impl_linux-64   conda-forge/linux-64::ld_impl_linux-64-2.36.1-hea4e1c9_2\n",
      "  libffi             conda-forge/linux-64::libffi-3.4.2-h9c3ff4c_4\n",
      "  libgcc-ng          conda-forge/linux-64::libgcc-ng-11.2.0-h1d223b6_11\n",
      "  libgomp            conda-forge/linux-64::libgomp-11.2.0-h1d223b6_11\n",
      "  libnsl             conda-forge/linux-64::libnsl-2.0.0-h7f98852_0\n",
      "  libstdcxx-ng       conda-forge/linux-64::libstdcxx-ng-11.2.0-he4da1e4_11\n",
      "  libzlib            conda-forge/linux-64::libzlib-1.2.11-h36c2ea0_1013\n",
      "  ncurses            conda-forge/linux-64::ncurses-6.2-h58526e2_4\n",
      "  openssl            conda-forge/linux-64::openssl-3.0.0-h7f98852_1\n",
      "  pip                conda-forge/noarch::pip-21.3.1-pyhd8ed1ab_0\n",
      "  python             conda-forge/linux-64::python-3.7.10-hf930737_104_cpython\n",
      "  python_abi         conda-forge/linux-64::python_abi-3.7-2_cp37m\n",
      "  readline           conda-forge/linux-64::readline-8.1-h46c0cb4_0\n",
      "  setuptools         conda-forge/linux-64::setuptools-58.2.0-py37h89c1867_0\n",
      "  sqlite             conda-forge/linux-64::sqlite-3.36.0-h9cd32fc_2\n",
      "  tk                 conda-forge/linux-64::tk-8.6.11-h27826a3_1\n",
      "  wheel              conda-forge/noarch::wheel-0.37.0-pyhd8ed1ab_1\n",
      "  xz                 conda-forge/linux-64::xz-5.2.5-h516909a_1\n",
      "  zlib               conda-forge/linux-64::zlib-1.2.11-h36c2ea0_1013\n",
      "\n",
      "\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate mtext2sql\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda create --name mtext2sql python=3.7 --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "00996d1e-e3a7-48f9-ba19-d3f9559b29d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!source activate mtext2sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e9814a8-cf9d-4654-9230-eaf8289a4b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install pytorch=1.5 cudatoolkit=10.2 -c pytorch --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14a04843-d6b2-4bbb-8d8f-7e7f8b06de25",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /opt/conda/lib/python3.7/site-packages (4.2.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.62.3)\n",
      "Requirement already satisfied: requests[socks] in /opt/conda/lib/python3.7/site-packages (from gdown) (2.25.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from gdown) (4.10.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown) (3.3.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->gdown) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.7)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 1)) (4.11.3)\n",
      "Requirement already satisfied: jsonnet~=0.14.0 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 2)) (0.14.0)\n",
      "Requirement already satisfied: nltk~=3.4 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 3)) (3.6.5)\n",
      "Requirement already satisfied: networkx~=2.2 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 4)) (2.5)\n",
      "Requirement already satisfied: entmax in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 5)) (1.0)\n",
      "Requirement already satisfied: pyrsistent~=0.14.9 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 6)) (0.14.11)\n",
      "Requirement already satisfied: bpemb~=0.2.11 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (0.2.12)\n",
      "Requirement already satisfied: simplemma in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (0.4.0)\n",
      "Requirement already satisfied: torchtext~=0.3.1 in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 9)) (0.3.1)\n",
      "Requirement already satisfied: attr in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 10)) (0.3.1)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 11)) (21.2.0)\n",
      "Requirement already satisfied: asdl in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 12)) (0.1.5)\n",
      "Requirement already satisfied: astor in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 13)) (0.8.1)\n",
      "Requirement already satisfied: pudb in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 14)) (2021.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers->-r requirements.txt (line 1)) (2021.10.21)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers->-r requirements.txt (line 1)) (3.3.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers->-r requirements.txt (line 1)) (1.19.5)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /opt/conda/lib/python3.7/site-packages (from transformers->-r requirements.txt (line 1)) (0.10.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.17 in /opt/conda/lib/python3.7/site-packages (from transformers->-r requirements.txt (line 1)) (0.0.19)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers->-r requirements.txt (line 1)) (4.62.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers->-r requirements.txt (line 1)) (4.8.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers->-r requirements.txt (line 1)) (2.25.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers->-r requirements.txt (line 1)) (6.0)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers->-r requirements.txt (line 1)) (0.0.46)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers->-r requirements.txt (line 1)) (21.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk~=3.4->-r requirements.txt (line 3)) (1.0.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk~=3.4->-r requirements.txt (line 3)) (8.0.3)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx~=2.2->-r requirements.txt (line 4)) (5.1.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from pyrsistent~=0.14.9->-r requirements.txt (line 6)) (1.16.0)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from bpemb~=0.2.11->-r requirements.txt (line 7)) (0.1.96)\n",
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.7/site-packages (from bpemb~=0.2.11->-r requirements.txt (line 7)) (4.1.2)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from torchtext~=0.3.1->-r requirements.txt (line 9)) (1.10.0)\n",
      "Requirement already satisfied: urwid>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from pudb->-r requirements.txt (line 14)) (2.1.2)\n",
      "Requirement already satisfied: pygments>=2.7.4 in /opt/conda/lib/python3.7/site-packages (from pudb->-r requirements.txt (line 14)) (2.10.0)\n",
      "Requirement already satisfied: jedi<1,>=0.18 in /opt/conda/lib/python3.7/site-packages (from pudb->-r requirements.txt (line 14)) (0.18.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.0.17->transformers->-r requirements.txt (line 1)) (3.10.0.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi<1,>=0.18->pudb->-r requirements.txt (line 14)) (0.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers->-r requirements.txt (line 1)) (2.4.7)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim->bpemb~=0.2.11->-r requirements.txt (line 7)) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim->bpemb~=0.2.11->-r requirements.txt (line 7)) (1.7.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers->-r requirements.txt (line 1)) (3.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers->-r requirements.txt (line 1)) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers->-r requirements.txt (line 1)) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers->-r requirements.txt (line 1)) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers->-r requirements.txt (line 1)) (1.26.7)\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown\n",
    "!pip install -r requirements.txt\n",
    "!python -c \"import nltk; nltk.download('stopwords'); nltk.download('punkt')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "11bfca5c-9bcb-4722-a226-52afbaab33a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c conda-forge jupyter_contrib_nbextensions --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e0419fc4-723e-461e-bcb2-2b3311bea08d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downdoad and unzip Spider Dataset\n",
      "Archive:  spider.zip\n",
      "   creating: spider/\n",
      "   creating: spider/database/\n",
      "   creating: spider/database/customer_deliveries/\n",
      "  inflating: spider/database/customer_deliveries/schema.sql  \n",
      "  inflating: spider/database/customer_deliveries/customer_deliveries.sqlite  \n",
      "   creating: spider/database/allergy_1/\n",
      "  inflating: spider/database/allergy_1/schema.sql  \n",
      "  inflating: spider/database/allergy_1/allergy_1.sqlite  \n",
      "   creating: spider/database/company_office/\n",
      "  inflating: spider/database/company_office/schema.sql  \n",
      "  inflating: spider/database/company_office/company_office.sqlite  \n",
      "   creating: spider/database/device/\n",
      "  inflating: spider/database/device/schema.sql  \n",
      "  inflating: spider/database/device/device.sqlite  \n",
      "   creating: spider/database/phone_1/\n",
      "  inflating: spider/database/phone_1/schema.sql  \n",
      "  inflating: spider/database/phone_1/phone_1.sqlite  \n",
      "   creating: spider/database/cre_Doc_Control_Systems/\n",
      "  inflating: spider/database/cre_Doc_Control_Systems/schema.sql  \n",
      "  inflating: spider/database/cre_Doc_Control_Systems/cre_Doc_Control_Systems.sqlite  \n",
      "   creating: spider/database/imdb/\n",
      "  inflating: spider/database/imdb/schema.sql  \n",
      "  inflating: spider/database/imdb/imdb.sqlite  \n",
      "   creating: spider/database/decoration_competition/\n",
      "  inflating: spider/database/decoration_competition/decoration_competition.sqlite  \n",
      "  inflating: spider/database/decoration_competition/schema.sql  \n",
      "   creating: spider/database/customers_campaigns_ecommerce/\n",
      "  inflating: spider/database/customers_campaigns_ecommerce/schema.sql  \n",
      "  inflating: spider/database/customers_campaigns_ecommerce/customers_campaigns_ecommerce.sqlite  \n",
      "   creating: spider/database/car_1/\n",
      "   creating: spider/database/car_1/data_csv/\n",
      "  inflating: spider/database/car_1/data_csv/countries.csv  \n",
      "  inflating: spider/database/car_1/data_csv/car-makers.csv  \n",
      "  inflating: spider/database/car_1/data_csv/continents.csv  \n",
      "  inflating: spider/database/car_1/data_csv/model-list.csv  \n",
      "  inflating: spider/database/car_1/data_csv/README.CARS.TXT  \n",
      "  inflating: spider/database/car_1/data_csv/cars.desc  \n",
      "  inflating: spider/database/car_1/data_csv/car-names.csv  \n",
      "  inflating: spider/database/car_1/data_csv/cars-data.csv  \n",
      "  inflating: spider/database/car_1/annotation.json  \n",
      "  inflating: spider/database/car_1/car_1.sql  \n",
      "  inflating: spider/database/car_1/q.txt  \n",
      "  inflating: spider/database/car_1/car_1.json  \n",
      " extracting: spider/database/car_1/link.txt  \n",
      "  inflating: spider/database/car_1/car_1.sqlite  \n",
      "   creating: spider/database/roller_coaster/\n",
      "  inflating: spider/database/roller_coaster/schema.sql  \n",
      "  inflating: spider/database/roller_coaster/roller_coaster.sqlite  \n",
      "   creating: spider/database/entrepreneur/\n",
      "  inflating: spider/database/entrepreneur/schema.sql  \n",
      "  inflating: spider/database/entrepreneur/entrepreneur.sqlite  \n",
      "   creating: spider/database/insurance_policies/\n",
      "  inflating: spider/database/insurance_policies/schema.sql  \n",
      "  inflating: spider/database/insurance_policies/insurance_policies.sqlite  \n",
      "   creating: spider/database/cre_Drama_Workshop_Groups/\n",
      "  inflating: spider/database/cre_Drama_Workshop_Groups/schema.sql  \n",
      "  inflating: spider/database/cre_Drama_Workshop_Groups/cre_Drama_Workshop_Groups.sqlite  \n",
      "   creating: spider/database/voter_1/\n",
      "  inflating: spider/database/voter_1/voter_1.sqlite  \n",
      "   creating: spider/database/journal_committee/\n",
      "  inflating: spider/database/journal_committee/schema.sql  \n",
      "  inflating: spider/database/journal_committee/journal_committee.sqlite  \n",
      "   creating: spider/database/performance_attendance/\n",
      "  inflating: spider/database/performance_attendance/schema.sql  \n",
      "  inflating: spider/database/performance_attendance/performance_attendance.sqlite  \n",
      "   creating: spider/database/store_1/\n",
      "  inflating: spider/database/store_1/schema.sql  \n",
      "  inflating: spider/database/store_1/store_1.sqlite  \n",
      "   creating: spider/database/school_player/\n",
      "  inflating: spider/database/school_player/schema.sql  \n",
      "  inflating: spider/database/school_player/school_player.sqlite  \n",
      "   creating: spider/database/scientist_1/\n",
      "  inflating: spider/database/scientist_1/schema.sql  \n",
      "  inflating: spider/database/scientist_1/scientist_1.sqlite  \n",
      "   creating: spider/database/student_transcripts_tracking/\n",
      "  inflating: spider/database/student_transcripts_tracking/schema.sql  \n",
      "  inflating: spider/database/student_transcripts_tracking/student_transcripts_tracking.sqlite  \n",
      "   creating: spider/database/department_store/\n",
      "  inflating: spider/database/department_store/schema.sql  \n",
      "  inflating: spider/database/department_store/department_store.sqlite  \n",
      "   creating: spider/database/cre_Doc_Template_Mgt/\n",
      "  inflating: spider/database/cre_Doc_Template_Mgt/schema.sql  \n",
      "  inflating: spider/database/cre_Doc_Template_Mgt/cre_Doc_Template_Mgt.sqlite  \n",
      "   creating: spider/database/local_govt_in_alabama/\n",
      "  inflating: spider/database/local_govt_in_alabama/schema.sql  \n",
      "  inflating: spider/database/local_govt_in_alabama/local_govt_in_alabama.sqlite  \n",
      "   creating: spider/database/browser_web/\n",
      "  inflating: spider/database/browser_web/schema.sql  \n",
      "  inflating: spider/database/browser_web/browser_web.sqlite  \n",
      "   creating: spider/database/cre_Docs_and_Epenses/\n",
      "  inflating: spider/database/cre_Docs_and_Epenses/schema.sql  \n",
      "  inflating: spider/database/cre_Docs_and_Epenses/cre_Docs_and_Epenses.sqlite  \n",
      "   creating: spider/database/apartment_rentals/\n",
      "  inflating: spider/database/apartment_rentals/schema.sql  \n",
      "  inflating: spider/database/apartment_rentals/apartment_rentals.sqlite  \n",
      "   creating: spider/database/flight_4/\n",
      " extracting: spider/database/flight_4/sql.txt  \n",
      "  inflating: spider/database/flight_4/flight_4.sqlite  \n",
      " extracting: spider/database/flight_4/link.txt  \n",
      "   creating: spider/database/hospital_1/\n",
      "  inflating: spider/database/hospital_1/schema.sql  \n",
      "  inflating: spider/database/hospital_1/hospital_1.sqlite  \n",
      "   creating: spider/database/soccer_1/\n",
      "  inflating: spider/database/soccer_1/schema.sql  \n",
      "  inflating: spider/database/soccer_1/soccer_1.sqlite  \n",
      "   creating: spider/database/gymnast/\n",
      "  inflating: spider/database/gymnast/schema.sql  \n",
      "  inflating: spider/database/gymnast/gymnast.sqlite  \n",
      "   creating: spider/database/soccer_2/\n",
      "  inflating: spider/database/soccer_2/schema.sql  \n",
      "  inflating: spider/database/soccer_2/soccer_2.sqlite  \n",
      "   creating: spider/database/formula_1/\n",
      "  inflating: spider/database/formula_1/formula_1.sql  \n",
      "   creating: spider/database/formula_1/data_csv/\n",
      "  inflating: spider/database/formula_1/data_csv/status.csv  \n",
      "  inflating: spider/database/formula_1/data_csv/qualifying.csv  \n",
      "  inflating: spider/database/formula_1/data_csv/results.csv  \n",
      "  inflating: spider/database/formula_1/data_csv/pitStops.csv  \n",
      "  inflating: spider/database/formula_1/data_csv/constructors.csv  \n",
      "  inflating: spider/database/formula_1/data_csv/lapTimes.csv  \n",
      "  inflating: spider/database/formula_1/data_csv/constructorResults.csv  \n",
      "  inflating: spider/database/formula_1/data_csv/circuits.csv  \n",
      "  inflating: spider/database/formula_1/data_csv/constructorStandings.csv  \n",
      "  inflating: spider/database/formula_1/data_csv/races.csv  \n",
      "  inflating: spider/database/formula_1/data_csv/seasons.csv  \n",
      "  inflating: spider/database/formula_1/data_csv/drivers.csv  \n",
      "  inflating: spider/database/formula_1/data_csv/driverStandings.csv  \n",
      " extracting: spider/database/formula_1/formula_1.splite  \n",
      "  inflating: spider/database/formula_1/annotation.json  \n",
      "  inflating: spider/database/formula_1/formula_1.sqlite  \n",
      "   creating: spider/database/workshop_paper/\n",
      "  inflating: spider/database/workshop_paper/schema.sql  \n",
      "  inflating: spider/database/workshop_paper/workshop_paper.sqlite  \n",
      "   creating: spider/database/shop_membership/\n",
      "  inflating: spider/database/shop_membership/schema.sql  \n",
      "  inflating: spider/database/shop_membership/shop_membership.sqlite  \n",
      "   creating: spider/database/candidate_poll/\n",
      "  inflating: spider/database/candidate_poll/schema.sql  \n",
      "  inflating: spider/database/candidate_poll/candidate_poll.sqlite  \n",
      "   creating: spider/database/hr_1/\n",
      "  inflating: spider/database/hr_1/schema.sql  \n",
      "  inflating: spider/database/hr_1/hr_1.sqlite  \n",
      "   creating: spider/database/storm_record/\n",
      "  inflating: spider/database/storm_record/schema.sql  \n",
      "  inflating: spider/database/storm_record/storm_record.sqlite  \n",
      "   creating: spider/database/ship_mission/\n",
      "  inflating: spider/database/ship_mission/ship_mission.sqlite  \n",
      "  inflating: spider/database/ship_mission/schema.sql  \n",
      "   creating: spider/database/coffee_shop/\n",
      "  inflating: spider/database/coffee_shop/schema.sql  \n",
      "  inflating: spider/database/coffee_shop/coffee_shop.sqlite  \n",
      "   creating: spider/database/bike_1/\n",
      "  inflating: spider/database/bike_1/schema.sql  \n",
      "  inflating: spider/database/bike_1/bike_1.sqlite  \n",
      "   creating: spider/database/activity_1/\n",
      "  inflating: spider/database/activity_1/schema.sql  \n",
      "  inflating: spider/database/activity_1/activity_1.sqlite  \n",
      "   creating: spider/database/film_rank/\n",
      "  inflating: spider/database/film_rank/schema.sql  \n",
      "  inflating: spider/database/film_rank/film_rank.sqlite  \n",
      "   creating: spider/database/program_share/\n",
      "  inflating: spider/database/program_share/schema.sql  \n",
      "  inflating: spider/database/program_share/program_share.sqlite  \n",
      "   creating: spider/database/company_1/\n",
      "  inflating: spider/database/company_1/company_1.sqlite  \n",
      "  inflating: spider/database/company_1/link.txt  \n",
      "   creating: spider/database/college_2/\n",
      "  inflating: spider/database/college_2/TextBookExampleSchema.sql  \n",
      "  inflating: spider/database/college_2/college_2.sqlite  \n",
      " extracting: spider/database/college_2/link.txt  \n",
      "   creating: spider/database/voter_2/\n",
      "  inflating: spider/database/voter_2/schema.sql  \n",
      "  inflating: spider/database/voter_2/voter_2.sqlite  \n",
      "   creating: spider/database/student_assessment/\n",
      "  inflating: spider/database/student_assessment/schema.sql  \n",
      "  inflating: spider/database/student_assessment/student_assessment.sqlite  \n",
      "   creating: spider/database/mountain_photos/\n",
      "  inflating: spider/database/mountain_photos/schema.sql  \n",
      "  inflating: spider/database/mountain_photos/mountain_photos.sqlite  \n",
      "   creating: spider/database/insurance_fnol/\n",
      "  inflating: spider/database/insurance_fnol/schema.sql  \n",
      "  inflating: spider/database/insurance_fnol/insurance_fnol.sqlite  \n",
      "   creating: spider/database/race_track/\n",
      "  inflating: spider/database/race_track/schema.sql  \n",
      "  inflating: spider/database/race_track/race_track.sqlite  \n",
      "   creating: spider/database/body_builder/\n",
      "  inflating: spider/database/body_builder/schema.sql  \n",
      "  inflating: spider/database/body_builder/body_builder.sqlite  \n",
      "   creating: spider/database/tracking_orders/\n",
      "  inflating: spider/database/tracking_orders/tracking_orders.sqlite  \n",
      "  inflating: spider/database/tracking_orders/schema.sql  \n",
      "   creating: spider/database/employee_hire_evaluation/\n",
      "  inflating: spider/database/employee_hire_evaluation/schema.sql  \n",
      "  inflating: spider/database/employee_hire_evaluation/employee_hire_evaluation.sqlite  \n",
      "   creating: spider/database/tracking_share_transactions/\n",
      "  inflating: spider/database/tracking_share_transactions/schema.sql  \n",
      "  inflating: spider/database/tracking_share_transactions/tracking_share_transactions.sqlite  \n",
      "   creating: spider/database/cre_Theme_park/\n",
      "  inflating: spider/database/cre_Theme_park/schema.sql  \n",
      "  inflating: spider/database/cre_Theme_park/cre_Theme_park.sqlite  \n",
      "   creating: spider/database/customers_and_products_contacts/\n",
      "  inflating: spider/database/customers_and_products_contacts/schema.sql  \n",
      "  inflating: spider/database/customers_and_products_contacts/customers_and_products_contacts.sqlite  \n",
      "   creating: spider/database/tracking_grants_for_research/\n",
      "  inflating: spider/database/tracking_grants_for_research/schema.sql  \n",
      "  inflating: spider/database/tracking_grants_for_research/tracking_grants_for_research.sqlite  \n",
      "   creating: spider/database/city_record/\n",
      "  inflating: spider/database/city_record/city_record.sqlite  \n",
      "  inflating: spider/database/city_record/schema.sql  \n",
      "   creating: spider/database/assets_maintenance/\n",
      "  inflating: spider/database/assets_maintenance/schema.sql  \n",
      "  inflating: spider/database/assets_maintenance/assets_maintenance.sqlite  \n",
      "   creating: spider/database/music_4/\n",
      "  inflating: spider/database/music_4/schema.sql  \n",
      "  inflating: spider/database/music_4/music_4.sqlite  \n",
      "   creating: spider/database/wrestler/\n",
      "  inflating: spider/database/wrestler/schema.sql  \n",
      "  inflating: spider/database/wrestler/wrestler.sqlite  \n",
      "   creating: spider/database/customer_complaints/\n",
      "  inflating: spider/database/customer_complaints/schema.sql  \n",
      "  inflating: spider/database/customer_complaints/customer_complaints.sqlite  \n",
      "   creating: spider/database/store_product/\n",
      "  inflating: spider/database/store_product/schema.sql  \n",
      "  inflating: spider/database/store_product/store_product.sqlite  \n",
      "   creating: spider/database/local_govt_mdm/\n",
      "  inflating: spider/database/local_govt_mdm/schema.sql  \n",
      "  inflating: spider/database/local_govt_mdm/local_govt_mdm.sqlite  \n",
      "   creating: spider/database/world_1/\n",
      "  inflating: spider/database/world_1/world_1.sqlite  \n",
      "  inflating: spider/database/world_1/world_1.json  \n",
      "   creating: spider/database/flight_1/\n",
      "  inflating: spider/database/flight_1/flight_1.sqlite  \n",
      "  inflating: spider/database/flight_1/schema.sql  \n",
      "   creating: spider/database/ship_1/\n",
      "  inflating: spider/database/ship_1/schema.sql  \n",
      "  inflating: spider/database/ship_1/ship_1.sqlite  \n",
      "   creating: spider/database/climbing/\n",
      "  inflating: spider/database/climbing/schema.sql  \n",
      "  inflating: spider/database/climbing/climbing.sqlite  \n",
      "   creating: spider/database/game_injury/\n",
      "  inflating: spider/database/game_injury/schema.sql  \n",
      "  inflating: spider/database/game_injury/game_injury.sqlite  \n",
      "   creating: spider/database/school_finance/\n",
      "  inflating: spider/database/school_finance/schema.sql  \n",
      "  inflating: spider/database/school_finance/school_finance.sqlite  \n",
      "   creating: spider/database/game_1/\n",
      "  inflating: spider/database/game_1/schema.sql  \n",
      "  inflating: spider/database/game_1/game_1.sqlite  \n",
      "   creating: spider/database/architecture/\n",
      "  inflating: spider/database/architecture/schema.sql  \n",
      "  inflating: spider/database/architecture/architecture.sqlite  \n",
      "   creating: spider/database/e_government/\n",
      "  inflating: spider/database/e_government/schema.sql  \n",
      "  inflating: spider/database/e_government/e_government.sqlite  \n",
      "   creating: spider/database/college_1/\n",
      "  inflating: spider/database/college_1/TinyCollege.sql  \n",
      "  inflating: spider/database/college_1/college_1.sqlite  \n",
      " extracting: spider/database/college_1/link.txt  \n",
      "   creating: spider/database/tracking_software_problems/\n",
      "  inflating: spider/database/tracking_software_problems/schema.sql  \n",
      "  inflating: spider/database/tracking_software_problems/tracking_software_problems.sqlite  \n",
      "   creating: spider/database/farm/\n",
      "  inflating: spider/database/farm/schema.sql  \n",
      "  inflating: spider/database/farm/farm.sqlite  \n",
      "   creating: spider/database/culture_company/\n",
      "  inflating: spider/database/culture_company/schema.sql  \n",
      "  inflating: spider/database/culture_company/culture_company.sqlite  \n",
      "   creating: spider/database/pilot_record/\n",
      "  inflating: spider/database/pilot_record/schema.sql  \n",
      "  inflating: spider/database/pilot_record/pilot_record.sqlite  \n",
      "   creating: spider/database/school_bus/\n",
      "  inflating: spider/database/school_bus/schema.sql  \n",
      "  inflating: spider/database/school_bus/school_bus.sqlite  \n",
      "   creating: spider/database/inn_1/\n",
      "   creating: spider/database/inn_1/data_csv/\n",
      "  inflating: spider/database/inn_1/data_csv/Rooms.csv  \n",
      "  inflating: spider/database/inn_1/data_csv/README.INN.TXT  \n",
      "  inflating: spider/database/inn_1/data_csv/Reservations_t.csv  \n",
      "  inflating: spider/database/inn_1/data_csv/Reservations.csv  \n",
      "  inflating: spider/database/inn_1/annotation.json  \n",
      "  inflating: spider/database/inn_1/inn_1.sqlite  \n",
      "  inflating: spider/database/inn_1/inn_1.sql  \n",
      "  inflating: spider/database/inn_1/q.txt  \n",
      "  inflating: spider/database/inn_1/change_date.py  \n",
      " extracting: spider/database/inn_1/link.txt  \n",
      "   creating: spider/database/local_govt_and_lot/\n",
      "  inflating: spider/database/local_govt_and_lot/schema.sql  \n",
      "  inflating: spider/database/local_govt_and_lot/local_govt_and_lot.sqlite  \n",
      "   creating: spider/database/aircraft/\n",
      "  inflating: spider/database/aircraft/schema.sql  \n",
      "  inflating: spider/database/aircraft/aircraft.sqlite  \n",
      "   creating: spider/database/real_estate_properties/\n",
      "  inflating: spider/database/real_estate_properties/schema.sql  \n",
      "  inflating: spider/database/real_estate_properties/real_estate_properties.sqlite  \n",
      "   creating: spider/database/music_2/\n",
      "  inflating: spider/database/music_2/schema.sql  \n",
      "  inflating: spider/database/music_2/music_2.sqlite  \n",
      "   creating: spider/database/match_season/\n",
      "  inflating: spider/database/match_season/schema.sql  \n",
      "  inflating: spider/database/match_season/match_season.sqlite  \n",
      "   creating: spider/database/county_public_safety/\n",
      "  inflating: spider/database/county_public_safety/schema.sql  \n",
      "  inflating: spider/database/county_public_safety/county_public_safety.sqlite  \n",
      "   creating: spider/database/network_1/\n",
      "  inflating: spider/database/network_1/schema.sql  \n",
      "  inflating: spider/database/network_1/network_1.sqlite  \n",
      "   creating: spider/database/yelp/\n",
      "  inflating: spider/database/yelp/schema.sql  \n",
      "  inflating: spider/database/yelp/yelp.sqlite  \n",
      "   creating: spider/database/solvency_ii/\n",
      "  inflating: spider/database/solvency_ii/schema.sql  \n",
      "  inflating: spider/database/solvency_ii/solvency_ii.sqlite  \n",
      "   creating: spider/database/singer/\n",
      "  inflating: spider/database/singer/schema.sql  \n",
      "  inflating: spider/database/singer/singer.sqlite  \n",
      "   creating: spider/database/college_3/\n",
      "  inflating: spider/database/college_3/schema.sql  \n",
      "  inflating: spider/database/college_3/college_3.sqlite  \n",
      "   creating: spider/database/movie_1/\n",
      "  inflating: spider/database/movie_1/schema.sql  \n",
      "  inflating: spider/database/movie_1/movie_1.sqlite  \n",
      "   creating: spider/database/twitter_1/\n",
      "  inflating: spider/database/twitter_1/twitter_1.sqlite  \n",
      "   creating: spider/database/twitter_1/queries/\n",
      "  inflating: spider/database/twitter_1/queries/oracle-dialects.xml  \n",
      "  inflating: spider/database/twitter_1/queries/sqlserver-dialects.xml  \n",
      "  inflating: spider/database/twitter_1/queries/postgres-dialects.xml  \n",
      "   creating: spider/database/music_1/\n",
      "  inflating: spider/database/music_1/schema.sql  \n",
      "  inflating: spider/database/music_1/music_1.sqlite  \n",
      "   creating: spider/database/company_employee/\n",
      "  inflating: spider/database/company_employee/schema.sql  \n",
      "  inflating: spider/database/company_employee/company_employee.sqlite  \n",
      "   creating: spider/database/pets_1/\n",
      "  inflating: spider/database/pets_1/schema.sql  \n",
      "  inflating: spider/database/pets_1/pets_1.sqlite  \n",
      "   creating: spider/database/gas_company/\n",
      "  inflating: spider/database/gas_company/schema.sql  \n",
      "  inflating: spider/database/gas_company/gas_company.sqlite  \n",
      "   creating: spider/database/academic/\n",
      "  inflating: spider/database/academic/schema.sql  \n",
      "  inflating: spider/database/academic/academic.sqlite  \n",
      "   creating: spider/database/battle_death/\n",
      "  inflating: spider/database/battle_death/schema.sql  \n",
      "  inflating: spider/database/battle_death/battle_death.sqlite  \n",
      "   creating: spider/database/election_representative/\n",
      "  inflating: spider/database/election_representative/schema.sql  \n",
      "  inflating: spider/database/election_representative/election_representative.sqlite  \n",
      "   creating: spider/database/dog_kennels/\n",
      "  inflating: spider/database/dog_kennels/schema.sql  \n",
      "  inflating: spider/database/dog_kennels/dog_kennels.sqlite  \n",
      "   creating: spider/database/products_for_hire/\n",
      "  inflating: spider/database/products_for_hire/products_for_hire.sqlite  \n",
      "  inflating: spider/database/products_for_hire/schema.sql  \n",
      "   creating: spider/database/e_learning/\n",
      "  inflating: spider/database/e_learning/schema.sql  \n",
      "  inflating: spider/database/e_learning/e_learning.sqlite  \n",
      "   creating: spider/database/entertainment_awards/\n",
      "  inflating: spider/database/entertainment_awards/schema.sql  \n",
      "  inflating: spider/database/entertainment_awards/entertainment_awards.sqlite  \n",
      "   creating: spider/database/tvshow/\n",
      "  inflating: spider/database/tvshow/schema.sql  \n",
      "  inflating: spider/database/tvshow/tvshow.sqlite  \n",
      "   creating: spider/database/theme_gallery/\n",
      "  inflating: spider/database/theme_gallery/schema.sql  \n",
      "  inflating: spider/database/theme_gallery/theme_gallery.sqlite  \n",
      "   creating: spider/database/document_management/\n",
      "  inflating: spider/database/document_management/schema.sql  \n",
      "  inflating: spider/database/document_management/document_management.sqlite  \n",
      "   creating: spider/database/university_basketball/\n",
      "  inflating: spider/database/university_basketball/schema.sql  \n",
      "  inflating: spider/database/university_basketball/university_basketball.sqlite  \n",
      "   creating: spider/database/orchestra/\n",
      "  inflating: spider/database/orchestra/schema.sql  \n",
      "  inflating: spider/database/orchestra/orchestra.sqlite  \n",
      "   creating: spider/database/restaurants/\n",
      "  inflating: spider/database/restaurants/schema.sql  \n",
      "  inflating: spider/database/restaurants/restaurants.sqlite  \n",
      "   creating: spider/database/flight_2/\n",
      "   creating: spider/database/flight_2/data_csv/\n",
      "  inflating: spider/database/flight_2/data_csv/README.AIRLINES.txt  \n",
      "  inflating: spider/database/flight_2/data_csv/airports100.csv  \n",
      "  inflating: spider/database/flight_2/data_csv/airlines.csv  \n",
      "  inflating: spider/database/flight_2/data_csv/flights.csv  \n",
      "  inflating: spider/database/flight_2/annotation.json  \n",
      "  inflating: spider/database/flight_2/flight_2.sql  \n",
      "  inflating: spider/database/flight_2/flight_2.json  \n",
      "  inflating: spider/database/flight_2/flight_2.sqlite  \n",
      "  inflating: spider/database/flight_2/q.txt  \n",
      " extracting: spider/database/flight_2/link.txt  \n",
      "   creating: spider/database/student_1/\n",
      "   creating: spider/database/student_1/data_csv/\n",
      "  inflating: spider/database/student_1/data_csv/README.STUDENTS.TXT  \n",
      "  inflating: spider/database/student_1/data_csv/list.csv  \n",
      "  inflating: spider/database/student_1/data_csv/teachers.csv  \n",
      "  inflating: spider/database/student_1/annotation.json  \n",
      "  inflating: spider/database/student_1/student_1.sql  \n",
      "  inflating: spider/database/student_1/student_1.sqlite  \n",
      "  inflating: spider/database/student_1/q.txt  \n",
      " extracting: spider/database/student_1/link.txt  \n",
      "   creating: spider/database/party_host/\n",
      "  inflating: spider/database/party_host/schema.sql  \n",
      "  inflating: spider/database/party_host/party_host.sqlite  \n",
      "   creating: spider/database/epinions_1/\n",
      "  inflating: spider/database/epinions_1/epinions_1.sqlite  \n",
      "   creating: spider/database/wedding/\n",
      "  inflating: spider/database/wedding/schema.sql  \n",
      "  inflating: spider/database/wedding/wedding.sqlite  \n",
      "   creating: spider/database/department_management/\n",
      "  inflating: spider/database/department_management/schema.sql  \n",
      "  inflating: spider/database/department_management/department_management.sqlite  \n",
      "   creating: spider/database/products_gen_characteristics/\n",
      "  inflating: spider/database/products_gen_characteristics/schema.sql  \n",
      "  inflating: spider/database/products_gen_characteristics/products_gen_characteristics.sqlite  \n",
      "   creating: spider/database/riding_club/\n",
      "  inflating: spider/database/riding_club/schema.sql  \n",
      "  inflating: spider/database/riding_club/riding_club.sqlite  \n",
      "   creating: spider/database/loan_1/\n",
      "  inflating: spider/database/loan_1/schema.sql  \n",
      "  inflating: spider/database/loan_1/loan_1.sqlite  \n",
      "   creating: spider/database/small_bank_1/\n",
      "  inflating: spider/database/small_bank_1/small_bank_1.sqlite  \n",
      "   creating: spider/database/flight_company/\n",
      "  inflating: spider/database/flight_company/schema.sql  \n",
      "  inflating: spider/database/flight_company/flight_company.sqlite  \n",
      "   creating: spider/database/manufactory_1/\n",
      "  inflating: spider/database/manufactory_1/schema.sql  \n",
      "  inflating: spider/database/manufactory_1/manufactory_1.sqlite  \n",
      "   creating: spider/database/customers_and_addresses/\n",
      "  inflating: spider/database/customers_and_addresses/schema.sql  \n",
      "  inflating: spider/database/customers_and_addresses/customers_and_addresses.sqlite  \n",
      "   creating: spider/database/station_weather/\n",
      "  inflating: spider/database/station_weather/schema.sql  \n",
      "  inflating: spider/database/station_weather/station_weather.sqlite  \n",
      "   creating: spider/database/manufacturer/\n",
      "  inflating: spider/database/manufacturer/schema.sql  \n",
      "  inflating: spider/database/manufacturer/manufacturer.sqlite  \n",
      "   creating: spider/database/phone_market/\n",
      "  inflating: spider/database/phone_market/schema.sql  \n",
      "  inflating: spider/database/phone_market/phone_market.sqlite  \n",
      "   creating: spider/database/wta_1/\n",
      "  inflating: spider/database/wta_1/wta_1.sql  \n",
      "  inflating: spider/database/wta_1/wta_1.sqlite  \n",
      "   creating: spider/database/perpetrator/\n",
      "  inflating: spider/database/perpetrator/schema.sql  \n",
      "  inflating: spider/database/perpetrator/perpetrator.sqlite  \n",
      "   creating: spider/database/train_station/\n",
      "  inflating: spider/database/train_station/schema.sql  \n",
      "  inflating: spider/database/train_station/train_station.sqlite  \n",
      "   creating: spider/database/medicine_enzyme_interaction/\n",
      "  inflating: spider/database/medicine_enzyme_interaction/schema.sql  \n",
      "  inflating: spider/database/medicine_enzyme_interaction/medicine_enzyme_interaction.sqlite  \n",
      "   creating: spider/database/chinook_1/\n",
      "  inflating: spider/database/chinook_1/annotation.json  \n",
      "  inflating: spider/database/chinook_1/chinook_1.sqlite  \n",
      "   creating: spider/database/driving_school/\n",
      "  inflating: spider/database/driving_school/schema.sql  \n",
      "  inflating: spider/database/driving_school/driving_school.sqlite  \n",
      "   creating: spider/database/news_report/\n",
      "  inflating: spider/database/news_report/schema.sql  \n",
      "  inflating: spider/database/news_report/news_report.sqlite  \n",
      "   creating: spider/database/icfp_1/\n",
      "  inflating: spider/database/icfp_1/icfp_1.sqlite  \n",
      "  inflating: spider/database/icfp_1/q.txt  \n",
      "  inflating: spider/database/icfp_1/link.txt  \n",
      "   creating: spider/database/cre_Doc_Tracking_DB/\n",
      "  inflating: spider/database/cre_Doc_Tracking_DB/schema.sql  \n",
      "  inflating: spider/database/cre_Doc_Tracking_DB/cre_Doc_Tracking_DB.sqlite  \n",
      "   creating: spider/database/behavior_monitoring/\n",
      "  inflating: spider/database/behavior_monitoring/schema.sql  \n",
      "  inflating: spider/database/behavior_monitoring/behavior_monitoring.sqlite  \n",
      "   creating: spider/database/restaurant_1/\n",
      "  inflating: spider/database/restaurant_1/schema.sql  \n",
      "  inflating: spider/database/restaurant_1/restaurant_1.sqlite  \n",
      "   creating: spider/database/scholar/\n",
      "  inflating: spider/database/scholar/schema.sql  \n",
      "  inflating: spider/database/scholar/scholar.sqlite  \n",
      "   creating: spider/database/product_catalog/\n",
      "  inflating: spider/database/product_catalog/schema.sql  \n",
      "  inflating: spider/database/product_catalog/product_catalog.sqlite  \n",
      "   creating: spider/database/csu_1/\n",
      "  inflating: spider/database/csu_1/schema.sql  \n",
      "  inflating: spider/database/csu_1/csu_1.sqlite  \n",
      "   creating: spider/database/debate/\n",
      "  inflating: spider/database/debate/schema.sql  \n",
      "  inflating: spider/database/debate/debate.sqlite  \n",
      "   creating: spider/database/railway/\n",
      "  inflating: spider/database/railway/schema.sql  \n",
      "  inflating: spider/database/railway/railway.sqlite  \n",
      "   creating: spider/database/protein_institute/\n",
      "  inflating: spider/database/protein_institute/schema.sql  \n",
      "  inflating: spider/database/protein_institute/protein_institute.sqlite  \n",
      "   creating: spider/database/machine_repair/\n",
      "  inflating: spider/database/machine_repair/schema.sql  \n",
      "  inflating: spider/database/machine_repair/machine_repair.sqlite  \n",
      "   creating: spider/database/insurance_and_eClaims/\n",
      "  inflating: spider/database/insurance_and_eClaims/schema.sql  \n",
      "  inflating: spider/database/insurance_and_eClaims/insurance_and_eClaims.sqlite  \n",
      "   creating: spider/database/museum_visit/\n",
      "  inflating: spider/database/museum_visit/museum_visit.sqlite  \n",
      "  inflating: spider/database/museum_visit/schema.sql  \n",
      "   creating: spider/database/wine_1/\n",
      "   creating: spider/database/wine_1/data_csv/\n",
      "  inflating: spider/database/wine_1/data_csv/appellations.csv  \n",
      "  inflating: spider/database/wine_1/data_csv/grapes.csv  \n",
      "  inflating: spider/database/wine_1/data_csv/wine.csv  \n",
      "  inflating: spider/database/wine_1/data_csv/README.WINE.txt  \n",
      "  inflating: spider/database/wine_1/annotation.json  \n",
      "  inflating: spider/database/wine_1/wine_1.sqlite  \n",
      "  inflating: spider/database/wine_1/wine_1.sql  \n",
      "   creating: spider/database/wine_1/.ipynb_checkpoints/\n",
      "  inflating: spider/database/wine_1/q.txt  \n",
      " extracting: spider/database/wine_1/link.txt  \n",
      "   creating: spider/database/swimming/\n",
      "  inflating: spider/database/swimming/schema.sql  \n",
      "  inflating: spider/database/swimming/swimming.sqlite  \n",
      "   creating: spider/database/election/\n",
      "  inflating: spider/database/election/election.sqlite  \n",
      "  inflating: spider/database/election/schema.sql  \n",
      "   creating: spider/database/dorm_1/\n",
      "  inflating: spider/database/dorm_1/schema.sql  \n",
      "  inflating: spider/database/dorm_1/dorm_1.sqlite  \n",
      "   creating: spider/database/course_teach/\n",
      "  inflating: spider/database/course_teach/schema.sql  \n",
      "  inflating: spider/database/course_teach/course_teach.sqlite  \n",
      "   creating: spider/database/club_1/\n",
      "  inflating: spider/database/club_1/schema.sql  \n",
      "  inflating: spider/database/club_1/club_1.sqlite  \n",
      "   creating: spider/database/concert_singer/\n",
      "  inflating: spider/database/concert_singer/schema.sql  \n",
      "  inflating: spider/database/concert_singer/concert_singer.sqlite  \n",
      "   creating: spider/database/sakila_1/\n",
      "  inflating: spider/database/sakila_1/schema.sql  \n",
      "  inflating: spider/database/sakila_1/sakila_1.sqlite  \n",
      "   creating: spider/database/customers_card_transactions/\n",
      "  inflating: spider/database/customers_card_transactions/schema.sql  \n",
      "  inflating: spider/database/customers_card_transactions/customers_card_transactions.sqlite  \n",
      "   creating: spider/database/poker_player/\n",
      "  inflating: spider/database/poker_player/schema.sql  \n",
      "  inflating: spider/database/poker_player/poker_player.sqlite  \n",
      "   creating: spider/database/customers_and_invoices/\n",
      "  inflating: spider/database/customers_and_invoices/schema.sql  \n",
      "  inflating: spider/database/customers_and_invoices/customers_and_invoices.sqlite  \n",
      "   creating: spider/database/musical/\n",
      "  inflating: spider/database/musical/schema.sql  \n",
      "  inflating: spider/database/musical/musical.sqlite  \n",
      "   creating: spider/database/sports_competition/\n",
      "  inflating: spider/database/sports_competition/schema.sql  \n",
      "  inflating: spider/database/sports_competition/sports_competition.sqlite  \n",
      "   creating: spider/database/network_2/\n",
      "  inflating: spider/database/network_2/network_2.sqlite  \n",
      "  inflating: spider/database/network_2/schema.sql  \n",
      "   creating: spider/database/geo/\n",
      "  inflating: spider/database/geo/schema.sql  \n",
      "  inflating: spider/database/geo/geo.sqlite  \n",
      "   creating: spider/database/party_people/\n",
      "  inflating: spider/database/party_people/schema.sql  \n",
      "  inflating: spider/database/party_people/party_people.sqlite  \n",
      "   creating: spider/database/cinema/\n",
      "  inflating: spider/database/cinema/schema.sql  \n",
      "  inflating: spider/database/cinema/cinema.sqlite  \n",
      "   creating: spider/database/baseball_1/\n",
      "  inflating: spider/database/baseball_1/schema.sql  \n",
      "  inflating: spider/database/baseball_1/baseball_1.sqlite  \n",
      "   creating: spider/database/book_2/\n",
      "  inflating: spider/database/book_2/schema.sql  \n",
      "  inflating: spider/database/book_2/book_2.sqlite  \n",
      "  inflating: spider/dev.json         \n",
      "  inflating: spider/train_others.json  \n",
      "  inflating: spider/.DS_Store        \n",
      "  inflating: spider/dev_gold.sql     \n",
      "  inflating: spider/train_spider.json  \n",
      "  inflating: spider/train_gold.sql   \n",
      "  inflating: spider/README.txt       \n",
      "  inflating: spider/tables.json      \n",
      "Procesing train_others\n",
      "\n",
      "Procesing train_spider\n",
      "patching file train_spider.json\n",
      "Hunk #1 succeeded at 436215 (offset 7025 lines).\n",
      "Hunk #2 succeeded at 436231 (offset 7025 lines).\n",
      "Hunk #3 succeeded at 436259 (offset 7025 lines).\n",
      "\n",
      "Procesing dev\n",
      "\n",
      "Build English dataset directory\n",
      "The original version of the Spider dataset is distributed under the CC BY-SA 4.0 license.\n",
      "Build Portuguese dataset directory\n",
      "The modified versions of train_spider.json, train_others.json, and dev.json are distributed under the CC BY-SA 4.0 license, respecting ShareAlike.\n",
      "Build Spanish dataset directory\n",
      "The modified versions of train_spider.json, train_others.json, and dev.json are distributed under the CC BY-SA 4.0 license, respecting ShareAlike.\n",
      "Build French dataset directory\n",
      "The modified versions of train_spider.json, train_others.json, and dev.json are distributed under the CC BY-SA 4.0 license, respecting ShareAlike.\n",
      "Build English and Portuguese dataset directory\n",
      "The modified versions of train_spider.json, train_others.json, and dev.json are distributed under the CC BY-SA 4.0 license, respecting ShareAlike.\n",
      "Build English, Portuguese, Spanish and French dataset directory\n",
      "The modified versions of train_spider.json, train_others.json, and dev.json are distributed under the CC BY-SA 4.0 license, respecting ShareAlike.\n",
      "Build English, Portuguese, Spanish, French, English data augmentation by rules and English data augmentation by backtranslation dataset directory\n",
      "The modified versions of train_spider.json, train_others.json, and dev.json are distributed under the CC BY-SA 4.0 license, respecting ShareAlike.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1_AckYkinAnhqmRQtGsQgUKAnTHxxX5J0\n",
      "To: /home/jupyter/gap-text2sql/mrat-sql-gap/spider.zip\n",
      "100%|ââââââââââ| 99.7M/99.7M [00:00<00:00, 329MB/s]\n",
      "100%|ââââââââââ| 1659/1659 [00:00<00:00, 3153.88it/s]\n",
      "100%|ââââââââââ| 7000/7000 [00:01<00:00, 4137.07it/s]\n",
      "100%|ââââââââââ| 1034/1034 [00:00<00:00, 4200.22it/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1rU79PipqU6XDIzqtYuS2Lg_LTYLbyN9U\n",
      "To: /home/jupyter/gap-text2sql/mrat-sql-gap/data/spider-pt/train_spider.json\n",
      "100%|ââââââââââ| 25.0M/25.0M [00:00<00:00, 350MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1no9qKojtDTAwFTm9MqZTOjjTupiEy7Ir\n",
      "To: /home/jupyter/gap-text2sql/mrat-sql-gap/data/spider-pt/train_others.json\n",
      "100%|ââââââââââ| 8.53M/8.53M [00:00<00:00, 295MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1HTNEUihVDuEg1hvLDbJd3yxXngJp3u4v\n",
      "To: /home/jupyter/gap-text2sql/mrat-sql-gap/data/spider-pt/dev.json\n",
      "100%|ââââââââââ| 3.64M/3.64M [00:00<00:00, 242MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1utYMsytUVRaozo50qjkQGwS2vDUWp4kD\n",
      "To: /home/jupyter/gap-text2sql/mrat-sql-gap/data/spider-es/train_spider.json\n",
      "100%|ââââââââââ| 25.3M/25.3M [00:00<00:00, 110MB/s] \n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1aSNetfAote7eG0lzDCJSPukT84abEtIN\n",
      "To: /home/jupyter/gap-text2sql/mrat-sql-gap/data/spider-es/train_others.json\n",
      "100%|ââââââââââ| 8.58M/8.58M [00:00<00:00, 300MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1UoFGQMvRkV7wBRyqhqu49Luu1Gs_HSi8\n",
      "To: /home/jupyter/gap-text2sql/mrat-sql-gap/data/spider-es/dev.json\n",
      "100%|ââââââââââ| 3.68M/3.68M [00:00<00:00, 226MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1VC8IiOSY2Oaq6eCJJjf0pplHtVXPhOXi\n",
      "To: /home/jupyter/gap-text2sql/mrat-sql-gap/data/spider-fr/train_spider.json\n",
      "100%|ââââââââââ| 25.2M/25.2M [00:00<00:00, 391MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1GmqiKa3-W1soEKadpY3L2fXiKLzf_6Ps\n",
      "To: /home/jupyter/gap-text2sql/mrat-sql-gap/data/spider-fr/train_others.json\n",
      "100%|ââââââââââ| 8.57M/8.57M [00:00<00:00, 334MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1NdALreT67okWPwIKuiVP6y2xWyZUtUf7\n",
      "To: /home/jupyter/gap-text2sql/mrat-sql-gap/data/spider-fr/dev.json\n",
      "100%|ââââââââââ| 3.67M/3.67M [00:00<00:00, 250MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1ph3ttcoaHMJvsI4yFhENHHuH_4M-UH53\n",
      "To: /home/jupyter/gap-text2sql/mrat-sql-gap/data/spider-en-pt/train_spider.json\n",
      "100%|ââââââââââ| 49.9M/49.9M [00:00<00:00, 236MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1odAFfyTM3N5y8QqQE5oUEt9CZZQ60CpS\n",
      "To: /home/jupyter/gap-text2sql/mrat-sql-gap/data/spider-en-pt/train_others.json\n",
      "100%|ââââââââââ| 17.0M/17.0M [00:00<00:00, 364MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1HOM5GNPiO_o4NeQTVzpgymyABPgUPbbr\n",
      "To: /home/jupyter/gap-text2sql/mrat-sql-gap/data/spider-en-pt/dev.json\n",
      "100%|ââââââââââ| 7.27M/7.27M [00:00<00:00, 301MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=18xoEkF5XdbfaN5SwqsbbMw89Y3iNvAa9\n",
      "To: /home/jupyter/gap-text2sql/mrat-sql-gap/data/spider-en-pt-es-fr/train_spider.json\n",
      "100%|ââââââââââ| 101M/101M [00:00<00:00, 294MB/s] \n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1n2U1pBzzRDAZuqmjloj6CV4Btf5sKfvd\n",
      "To: /home/jupyter/gap-text2sql/mrat-sql-gap/data/spider-en-pt-es-fr/train_others.json\n",
      "100%|ââââââââââ| 34.2M/34.2M [00:00<00:00, 369MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1diKAP4BGccFzupvf3HCcPleRP5EMqSHM\n",
      "To: /home/jupyter/gap-text2sql/mrat-sql-gap/data/spider-en-pt-es-fr/dev.json\n",
      "100%|ââââââââââ| 14.6M/14.6M [00:00<00:00, 54.0MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1gvrpgytqswz8wKx2qTZqofVqM3S32Wm8\n",
      "To: /home/jupyter/gap-text2sql/mrat-sql-gap/data/spider-en-pt-es-fr-enr-enb/train_spider.json\n",
      "100%|ââââââââââ| 150M/150M [00:00<00:00, 294MB/s] \n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1M2ZWYAXK-28I6ovlGSJ_D6pJzo0wliJP\n",
      "To: /home/jupyter/gap-text2sql/mrat-sql-gap/data/spider-en-pt-es-fr-enr-enb/train_others.json\n",
      "100%|ââââââââââ| 51.3M/51.3M [00:00<00:00, 181MB/s] \n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1lir8r3NcvrpthT5aK4TXz4eYSDHXQmcy\n",
      "To: /home/jupyter/gap-text2sql/mrat-sql-gap/data/spider-en-pt-es-fr-enr-enb/dev.json\n",
      "100%|ââââââââââ| 14.6M/14.6M [00:00<00:00, 328MB/s]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "chmod +x setup.sh\n",
    "./setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3fd1aa-1890-437d-8743-de35a3119f6b",
   "metadata": {},
   "source": [
    "# Setup BRIDGE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6668d0e-0275-48b1-9e68-78d597e9cbe2",
   "metadata": {},
   "source": [
    "## InstalaÃ§Ã£o das dependÃªncias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c5e1f90-f09d-4112-ba22-7f3849da38fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter\n"
     ]
    }
   ],
   "source": [
    "%cd /home/jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5b0ad89-aeb3-47b4-91f5-d510745387d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'TabularSemanticParsing'...\n",
      "remote: Enumerating objects: 422, done.\u001b[K\n",
      "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "remote: Total 422 (delta 0), reused 0 (delta 0), pack-reused 419\u001b[K\n",
      "Receiving objects: 100% (422/422), 1.12 MiB | 20.20 MiB/s, done.\n",
      "Resolving deltas: 100% (224/224), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/salesforce/TabularSemanticParsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ed600ff6-9f48-4a46-8a22-6cf4d0499541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/TabularSemanticParsing\n"
     ]
    }
   ],
   "source": [
    "%cd TabularSemanticParsing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b30bd37b-1426-42ad-93d0-e86c0546f66e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.10.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.11.1-cp37-cp37m-manylinux1_x86_64.whl (23.3 MB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 23.3 MB 7.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (8.3.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.19.5)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.11.1\n",
      "Collecting revtok==0.0.3\n",
      "  Downloading revtok-0.0.3-py3-none-any.whl (4.3 kB)\n",
      "Collecting tqdm==4.27\n",
      "  Downloading tqdm-4.27.0-py2.py3-none-any.whl (44 kB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 44 kB 2.7 MB/s             \n",
      "\u001b[?25hCollecting torchvision==0.2.1\n",
      "  Downloading torchvision-0.2.1-py2.py3-none-any.whl (54 kB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 54 kB 3.5 MB/s             \n",
      "\u001b[?25hCollecting mo-future>=2.20\n",
      "  Downloading mo-future-5.17.21182.tar.gz (9.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyparsing==2.3.0\n",
      "  Downloading pyparsing-2.3.0-py2.py3-none-any.whl (59 kB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 59 kB 8.7 MB/s             \n",
      "\u001b[?25hCollecting wandb==0.8.30\n",
      "  Downloading wandb-0.8.30-py2.py3-none-any.whl (1.4 MB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 1.4 MB 59.4 MB/s            \n",
      "\u001b[?25hCollecting n2w\n",
      "  Downloading n2w-0.1.3.tar.gz (1.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting matplotlib==3.0.2\n",
      "  Downloading matplotlib-3.0.2-cp37-cp37m-manylinux1_x86_64.whl (12.9 MB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 12.9 MB 3.7 MB/s            \n",
      "\u001b[?25hCollecting transformers==2.8.0\n",
      "  Downloading transformers-2.8.0-py3-none-any.whl (563 kB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 563 kB 58.1 MB/s            \n",
      "\u001b[?25hCollecting asciitree\n",
      "  Downloading asciitree-0.3.3.tar.gz (4.0 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting apex\n",
      "  Downloading apex-0.9.10dev.tar.gz (36 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting nltk==3.4.5\n",
      "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 1.5 MB 51.3 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting rapidfuzz==0.9.1\n",
      "  Downloading rapidfuzz-0.9.1-cp37-cp37m-manylinux2010_x86_64.whl (2.0 MB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 2.0 MB 81.6 MB/s            \n",
      "\u001b[?25hCollecting records\n",
      "  Downloading records-0.5.3-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: babel in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 17)) (2.9.1)\n",
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 19)) (1.7.1)\n",
      "Collecting sqlalchemy==1.3.20\n",
      "  Downloading SQLAlchemy-1.3.20-cp37-cp37m-manylinux2010_x86_64.whl (1.3 MB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 1.3 MB 56.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from torchvision==0.2.1->-r requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision==0.2.1->-r requirements.txt (line 3)) (1.19.5)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.7/site-packages (from torchvision==0.2.1->-r requirements.txt (line 3)) (8.3.2)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from torchvision==0.2.1->-r requirements.txt (line 3)) (1.10.0)\n",
      "Collecting nvidia-ml-py3>=7.352.0\n",
      "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gql==0.2.0\n",
      "  Downloading gql-0.2.0.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting subprocess32>=3.5.3\n",
      "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 97 kB 8.7 MB/s             \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb==0.8.30->-r requirements.txt (line 6)) (3.1.24)\n",
      "Requirement already satisfied: Click>=7.0 in /opt/conda/lib/python3.7/site-packages (from wandb==0.8.30->-r requirements.txt (line 6)) (8.0.3)\n",
      "Requirement already satisfied: requests>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb==0.8.30->-r requirements.txt (line 6)) (2.25.1)\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
      "Collecting watchdog>=0.8.3\n",
      "  Downloading watchdog-2.1.6-py3-none-manylinux2014_x86_64.whl (76 kB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 76 kB 7.1 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from wandb==0.8.30->-r requirements.txt (line 6)) (0.4.0)\n",
      "Collecting configparser>=3.8.1\n",
      "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from wandb==0.8.30->-r requirements.txt (line 6)) (2.8.2)\n",
      "Collecting sentry-sdk>=0.4.0\n",
      "  Downloading sentry_sdk-1.4.3-py2.py3-none-any.whl (139 kB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 139 kB 55.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from wandb==0.8.30->-r requirements.txt (line 6)) (5.8.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.7/site-packages (from wandb==0.8.30->-r requirements.txt (line 6)) (6.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.0.2->-r requirements.txt (line 8)) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib==3.0.2->-r requirements.txt (line 8)) (1.3.2)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from transformers==2.8.0->-r requirements.txt (line 9)) (0.1.96)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers==2.8.0->-r requirements.txt (line 9)) (3.3.1)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.19.3-py3-none-any.whl (131 kB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 131 kB 59.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers==2.8.0->-r requirements.txt (line 9)) (0.0.46)\n",
      "Collecting tokenizers==0.5.2\n",
      "  Downloading tokenizers-0.5.2-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 5.6 MB 20.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers==2.8.0->-r requirements.txt (line 9)) (2021.10.21)\n",
      "Collecting graphql-core<2,>=0.5.0\n",
      "  Downloading graphql-core-1.1.tar.gz (70 kB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 70 kB 10.3 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting promise<3,>=2.0\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: markdown in /opt/conda/lib/python3.7/site-packages (from n2w->-r requirements.txt (line 7)) (3.3.4)\n",
      "Collecting cryptacular\n",
      "  Downloading cryptacular-1.6.2.tar.gz (75 kB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 75 kB 5.9 MB/s             \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing wheel metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting zope.sqlalchemy\n",
      "  Downloading zope.sqlalchemy-1.6-py2.py3-none-any.whl (22 kB)\n",
      "Collecting velruse>=1.0.3\n",
      "  Downloading velruse-1.1.1.tar.gz (709 kB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 709 kB 58.3 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyramid>1.1.2\n",
      "  Downloading pyramid-2.0-py3-none-any.whl (246 kB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 246 kB 79.7 MB/s            \n",
      "\u001b[?25hCollecting pyramid_mailer\n",
      "  Downloading pyramid_mailer-0.15.1-py2.py3-none-any.whl (19 kB)\n",
      "Collecting wtforms\n",
      "  Downloading WTForms-2.3.3-py2.py3-none-any.whl (169 kB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 169 kB 57.0 MB/s            \n",
      "\u001b[?25hCollecting wtforms-recaptcha\n",
      "  Downloading wtforms_recaptcha-0.3.2-py2.py3-none-any.whl (7.5 kB)\n",
      "Collecting openpyxl<2.5.0\n",
      "  Downloading openpyxl-2.4.11.tar.gz (158 kB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 158 kB 54.2 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting docopt\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tablib>=0.11.4\n",
      "  Downloading tablib-3.0.0-py3-none-any.whl (47 kB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 47 kB 6.5 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: pytz>=2015.7 in /opt/conda/lib/python3.7/site-packages (from babel->-r requirements.txt (line 17)) (2021.3)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from Click>=7.0->wandb==0.8.30->-r requirements.txt (line 6)) (4.8.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb==0.8.30->-r requirements.txt (line 6)) (4.0.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from GitPython>=1.0.0->wandb==0.8.30->-r requirements.txt (line 6)) (3.10.0.2)\n",
      "Collecting jdcal\n",
      "  Downloading jdcal-1.4.1-py2.py3-none-any.whl (9.5 kB)\n",
      "Collecting et_xmlfile\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting translationstring>=0.4\n",
      "  Downloading translationstring-1.4-py2.py3-none-any.whl (15 kB)\n",
      "Collecting webob>=1.8.3\n",
      "  Downloading WebOb-1.8.7-py2.py3-none-any.whl (114 kB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 114 kB 58.9 MB/s            \n",
      "\u001b[?25hCollecting hupper>=1.5\n",
      "  Downloading hupper-1.10.3-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from pyramid>1.1.2->apex->-r requirements.txt (line 11)) (58.2.0)\n",
      "Collecting zope.deprecation>=3.5.0\n",
      "  Downloading zope.deprecation-4.4.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting venusian>=1.0\n",
      "  Downloading venusian-3.0.0-py3-none-any.whl (13 kB)\n",
      "Collecting plaster\n",
      "  Downloading plaster-1.0-py2.py3-none-any.whl (14 kB)\n",
      "Collecting zope.interface>=3.8.0\n",
      "  Downloading zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251 kB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 251 kB 84.4 MB/s            \n",
      "\u001b[?25hCollecting plaster-pastedeploy\n",
      "  Downloading plaster_pastedeploy-0.7-py2.py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.0.0->wandb==0.8.30->-r requirements.txt (line 6)) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.0.0->wandb==0.8.30->-r requirements.txt (line 6)) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.0.0->wandb==0.8.30->-r requirements.txt (line 6)) (1.26.7)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests>=2.0.0->wandb==0.8.30->-r requirements.txt (line 6)) (4.0.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from velruse>=1.0.3->apex->-r requirements.txt (line 11)) (1.3.0)\n",
      "Collecting anykeystore\n",
      "  Downloading anykeystore-0.2.tar.gz (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting python3-openid\n",
      "  Downloading python3_openid-3.2.0-py3-none-any.whl (133 kB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 133 kB 54.1 MB/s            \n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 79 kB 9.9 MB/s             \n",
      "\u001b[?25hCollecting botocore<1.23.0,>=1.22.3\n",
      "  Downloading botocore-1.22.3-py3-none-any.whl (8.0 MB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 8.0 MB 54.7 MB/s            \n",
      "\u001b[?25hCollecting pbkdf2\n",
      "  Downloading pbkdf2-1.3.tar.gz (6.4 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transaction\n",
      "  Downloading transaction-3.0.1-py2.py3-none-any.whl (47 kB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 47 kB 6.9 MB/s             \n",
      "\u001b[?25hCollecting repoze.sendmail>=4.1\n",
      "  Downloading repoze.sendmail-4.4.1-py2.py3-none-any.whl (41 kB)\n",
      "     |ââââââââââââââââââââââââââââââââ| 41 kB 62 kB/s              \n",
      "\u001b[?25hRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers==2.8.0->-r requirements.txt (line 9)) (1.0.1)\n",
      "Requirement already satisfied: MarkupSafe in /opt/conda/lib/python3.7/site-packages (from wtforms->apex->-r requirements.txt (line 11)) (2.0.1)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb==0.8.30->-r requirements.txt (line 6)) (3.0.5)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->Click>=7.0->wandb==0.8.30->-r requirements.txt (line 6)) (3.6.0)\n",
      "Collecting PasteDeploy>=2.0\n",
      "  Downloading PasteDeploy-2.1.1-py2.py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.7/site-packages (from python3-openid->velruse>=1.0.3->apex->-r requirements.txt (line 11)) (0.7.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->velruse>=1.0.3->apex->-r requirements.txt (line 11)) (3.1.1)\n",
      "Building wheels for collected packages: nltk, gql, mo-future, n2w, asciitree, apex, nvidia-ml-py3, openpyxl, subprocess32, velruse, cryptacular, docopt, graphql-core, promise, anykeystore, pbkdf2\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449920 sha256=2e2c4864fdc6150f734b7cc52b930ada7318cb6c6a1dafa98576456f98c2cc08\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n",
      "  Building wheel for gql (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gql: filename=gql-0.2.0-py3-none-any.whl size=7639 sha256=524342731bf7706d2f9189a53fef464ffb59eb23b5476b9350e45b589defd97d\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/b6/9a/56/5456fd32264a8fc53eefcb2f74e24e99a7ef4eb40a9af5c905\n",
      "  Building wheel for mo-future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mo-future: filename=mo_future-5.17.21182-py3-none-any.whl size=10031 sha256=225cc74ea6f6eeadd226dc9e6c6382ad9c187c39dbbda8484c22a9970fd7b360\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/db/3e/9b/81e40191ff9bbef8e92a9dd405ad46dbf4115fb9c019619082\n",
      "  Building wheel for n2w (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for n2w: filename=n2w-0.1.3-py3-none-any.whl size=2616 sha256=86aebbd7f46f86e798730ff49fed620515c782edd1739e732c28cb1b66a041fc\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/85/5d/cf/5f4b9e790c93237040b543640d18421ed1743365e5290b36d1\n",
      "  Building wheel for asciitree (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for asciitree: filename=asciitree-0.3.3-py3-none-any.whl size=5051 sha256=6786f99bce147cf807180a3dc489de783072296b8afb25009aafbfb9b4fb6deb\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/12/1c/38/0def51e15add93bff3f4bf9c248b94db0839b980b8535e72a0\n",
      "  Building wheel for apex (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for apex: filename=apex-0.9.10.dev0-py3-none-any.whl size=46466 sha256=e71cffad023e8df6e01db19806038119e80a116c0b1d7e39d70cefd5389cf6e2\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/f0/00/2b/37b6028388b451bbd30230c62f5238aef3b11fdff9503138bc\n",
      "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19191 sha256=c7fcaca6b268443ceec09b4c89641550cd9ad967e4ee45965d8512f4039b0623\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/df/99/da/c34f202dc8fd1dffd35e0ecf1a7d7f8374ca05fbcbaf974b83\n",
      "  Building wheel for openpyxl (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openpyxl: filename=openpyxl-2.4.11-py2.py3-none-any.whl size=222839 sha256=d83d682ba8d9be2ee2cca2c77de02488aa846ba50146a78bde37192cd0ad2627\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/ee/c3/67/b0c36cbd1242ea70054d400cad5192f02728eb67014192fd85\n",
      "  Building wheel for subprocess32 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=4fe643c7e25507133806f6f2fb8da0d9ad94d63c2e7f11fb2123bdf38525b104\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
      "  Building wheel for velruse (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for velruse: filename=velruse-1.1.1-py3-none-any.whl size=50937 sha256=07c1cd61f5ec06c7ca39b6e4583dc2fc16a37455a9b585d919cda89eac6d2756\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/61/f0/95/7f8b3bb1cce5c78ca7a7922cf72383f886f70e358f0a18d60b\n",
      "  Building wheel for cryptacular (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for cryptacular: filename=cryptacular-1.6.2-cp37-cp37m-linux_x86_64.whl size=65241 sha256=07efd516685f8543028940bc27f2b48a0c3ece2c702ed67db89bb23ef6b68b5b\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/fc/e8/c2/4b71f45f434136d31df930960b8a916bb36ebe2144479a37a1\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13724 sha256=70d91fef1120351d266f861ceb7d72e800be84a8e03515191d245a88c0152290\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
      "  Building wheel for graphql-core (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for graphql-core: filename=graphql_core-1.1-py3-none-any.whl size=104649 sha256=264d4453900adbf9a4b9aacccfe030181d2c325a5862ee6b519ab1ffa5d2cde4\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/6b/fd/8c/a20dd591c1a554070cc33fb58042867e6ac1c85395abe2e57a\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21502 sha256=97df32f50c086c5982656f0a1db9351e143536b45ea7eb407b9e3c587e5a70f2\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/29/93/c6/762e359f8cb6a5b69c72235d798804cae523bbe41c2aa8333d\n",
      "  Building wheel for anykeystore (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for anykeystore: filename=anykeystore-0.2-py3-none-any.whl size=17042 sha256=f4c63463a7d91892f88e87a7175b9e0bd7613e35bf1ea97059703c7dccced0d4\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/12/14/12/afad2dc2b7ea0884e12f260b0723b49b98f39f08adb7b0414f\n",
      "  Building wheel for pbkdf2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pbkdf2: filename=pbkdf2-1.3-py3-none-any.whl size=5103 sha256=11a11a3a7391ee59b8667c08dca01eaf44dd3ce538b5aadb7774c512d14e548f\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/49/16/ea/daca297d70ee0782ac6e16e83b2c55b2ca42a2113750bc0489\n",
      "Successfully built nltk gql mo-future n2w asciitree apex nvidia-ml-py3 openpyxl subprocess32 velruse cryptacular docopt graphql-core promise anykeystore pbkdf2\n",
      "Installing collected packages: zope.interface, plaster, PasteDeploy, jmespath, zope.deprecation, webob, venusian, translationstring, transaction, promise, plaster-pastedeploy, hupper, botocore, wtforms, tqdm, sqlalchemy, s3transfer, repoze.sendmail, python3-openid, pyramid, pbkdf2, jdcal, graphql-core, et-xmlfile, anykeystore, zope.sqlalchemy, wtforms-recaptcha, watchdog, velruse, tokenizers, tablib, subprocess32, shortuuid, sentry-sdk, pyramid-mailer, pyparsing, openpyxl, nvidia-ml-py3, gql, docopt, cryptacular, configparser, boto3, wandb, transformers, torchvision, tabulate, revtok, records, rapidfuzz, nltk, n2w, mo-future, matplotlib, asciitree, apex\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.62.3\n",
      "    Uninstalling tqdm-4.62.3:\n",
      "      Successfully uninstalled tqdm-4.62.3\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 1.4.26\n",
      "    Uninstalling SQLAlchemy-1.4.26:\n",
      "      Successfully uninstalled SQLAlchemy-1.4.26\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.10.3\n",
      "    Uninstalling tokenizers-0.10.3:\n",
      "      Successfully uninstalled tokenizers-0.10.3\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 2.4.7\n",
      "    Uninstalling pyparsing-2.4.7:\n",
      "      Successfully uninstalled pyparsing-2.4.7\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.11.3\n",
      "    Uninstalling transformers-4.11.3:\n",
      "      Successfully uninstalled transformers-4.11.3\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.11.1\n",
      "    Uninstalling torchvision-0.11.1:\n",
      "      Successfully uninstalled torchvision-0.11.1\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.6.5\n",
      "    Uninstalling nltk-3.6.5:\n",
      "      Successfully uninstalled nltk-3.6.5\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.4.3\n",
      "    Uninstalling matplotlib-3.4.3:\n",
      "      Successfully uninstalled matplotlib-3.4.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "papermill 2.3.3 requires tqdm>=4.32.2, but you have tqdm 4.27.0 which is incompatible.\n",
      "pandas-profiling 3.1.0 requires matplotlib>=3.2.0, but you have matplotlib 3.0.2 which is incompatible.\n",
      "pandas-profiling 3.1.0 requires tqdm>=4.48.2, but you have tqdm 4.27.0 which is incompatible.\n",
      "httplib2 0.20.1 requires pyparsing<3,>=2.4.2, but you have pyparsing 2.3.0 which is incompatible.\u001b[0m\n",
      "Successfully installed PasteDeploy-2.1.1 anykeystore-0.2 apex-0.9.10.dev0 asciitree-0.3.3 boto3-1.19.3 botocore-1.22.3 configparser-5.0.2 cryptacular-1.6.2 docopt-0.6.2 et-xmlfile-1.1.0 gql-0.2.0 graphql-core-1.1 hupper-1.10.3 jdcal-1.4.1 jmespath-0.10.0 matplotlib-3.0.2 mo-future-5.17.21182 n2w-0.1.3 nltk-3.4.5 nvidia-ml-py3-7.352.0 openpyxl-2.4.11 pbkdf2-1.3 plaster-1.0 plaster-pastedeploy-0.7 promise-2.3 pyparsing-2.3.0 pyramid-2.0 pyramid-mailer-0.15.1 python3-openid-3.2.0 rapidfuzz-0.9.1 records-0.5.3 repoze.sendmail-4.4.1 revtok-0.0.3 s3transfer-0.5.0 sentry-sdk-1.4.3 shortuuid-1.0.1 sqlalchemy-1.3.20 subprocess32-3.5.4 tablib-3.0.0 tabulate-0.8.9 tokenizers-0.5.2 torchvision-0.2.1 tqdm-4.27.0 transaction-3.0.1 transformers-2.8.0 translationstring-1.4 velruse-1.1.1 venusian-3.0.0 wandb-0.8.30 watchdog-2.1.6 webob-1.8.7 wtforms-2.3.3 wtforms-recaptcha-0.3.2 zope.deprecation-4.4.0 zope.interface-5.4.0 zope.sqlalchemy-1.6\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision\n",
    "!python3 -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4bd760b7-c02a-4d82-bdbf-48e3d4b15580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mo-future in /opt/conda/lib/python3.7/site-packages (5.17.21182)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install mo-future --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "50514da5-34fb-4fd0-a980-90b52726c3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTHONPATH=`pwd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "94d911ae-22fc-4995-885c-d2aa020989b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/runpy.py:125: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!export PYTHONPATH=`pwd` && python -m nltk.downloader punkt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69db1e19-8e5d-41aa-8f0a-7d6555bf018d",
   "metadata": {},
   "source": [
    "## Move arquivos entre os projetos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fbd2ed07-bd09-4ee7-9a1c-f7525e3f8980",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv '/home/jupyter/gap-text2sql/mrat-sql-gap/data/spider-en-pt/database' '/home/jupyter/TabularSemanticParsing/data/spider'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1179bfa1-0e64-4654-afa6-0ccbb5253189",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv '/home/jupyter/gap-text2sql/mrat-sql-gap/data/spider-en-pt/dev.json' '/home/jupyter/TabularSemanticParsing/data/spider'\n",
    "!mv '/home/jupyter/gap-text2sql/mrat-sql-gap/data/spider-en-pt/tables.json' '/home/jupyter/TabularSemanticParsing/data/spider'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65125d5a-9d78-4843-875a-e86078bd3644",
   "metadata": {},
   "source": [
    "## Baixa arquivo de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e4c6d48-008f-4741-af92-d13b7cc9956b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/TabularSemanticParsing/data/spider\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Ve2i3-oxBbrV87_UqHI09q1aKjFlZrws\n",
      "To: /home/jupyter/TabularSemanticParsing/data/spider/train.json\n",
      "100%|ââââââââââââââââââââââââââââââââââââââ| 67.0M/67.0M [00:00<00:00, 74.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Merge entre os arquivos train_spider.json e train_others.json realizado manualmente\n",
    "%cd '/home/jupyter/TabularSemanticParsing/data/spider'\n",
    "!gdown --id '1Ve2i3-oxBbrV87_UqHI09q1aKjFlZrws'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135e1871-dd68-4f5d-bd5f-542e93c92dcc",
   "metadata": {},
   "source": [
    "## PrÃ©-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2c81e268-8f71-4909-88c2-0ed3edb57168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/TabularSemanticParsing\n"
     ]
    }
   ],
   "source": [
    "%cd '/home/jupyter/TabularSemanticParsing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a5bb26-4eff-47fe-9434-ac584429f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 data/spider/scripts/amend_missing_foreign_keys.py data/spider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475de6a4-9b57-4a8a-a8a7-9f13004eb8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "./experiment-bridge.sh configs/bridge/spider-bridge-bert-large.sh --process_data 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0df99a-2647-4b2e-bae3-7c191e96e2f8",
   "metadata": {},
   "source": [
    "# Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df7bfb4-fba1-4018-9492-76ce22ff06ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpar o cache\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import gc\n",
    "# del bridge \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230f4e2c-9b98-472c-8b2d-778e0f0cb66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tor# memory footprint support libraries/code\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isnât guaranteed\n",
    "gpu = GPUs[0]\n",
    "def printm():\n",
    " process = psutil.Process(os.getpid())\n",
    " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "printm()ch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "12d7a55b-6367-4b00-b40f-9dfd795e3f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "!./experiment-bridge.sh configs/bridge/spider-bridge-bert-large.sh --train 0"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m82",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m82"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
